{"componentChunkName":"component---src-templates-tags-tsx","path":"/tags/machine-learning","result":{"data":{"site":{"siteMetadata":{"title":"Jeff Willette","description":"developer blog for Jeff Willette","keywords":"Jeff Willette,jeffwillette.github.io","author":"Jeff Willette"}},"allMdx":{"edges":[{"node":{"frontmatter":{"title":"Pattern Recognition and Machine Learning: Chapter 1 Notes","createdAt":"2019-05-07T00:59:25.732Z","updatedAt":"2019-07-21T21:59:47.638Z","categories":["Pattern Recognition","Machine Learning","Chapter 1"]},"fields":{"slug":"/blog/pattern-recognition-and-machine-learning-notes/chapter-1/"},"timeToRead":4,"excerpt":"supervised learning  has both input and target vectors that have been labeled clasification  assigns each input vector to a discrete set of…"}},{"node":{"frontmatter":{"title":"Anomaly Detection","createdAt":"2019-03-20T14:26:44.585Z","updatedAt":"2019-07-21T15:16:49.628Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/anomaly-detection/"},"timeToRead":1,"excerpt":"Anomaly detection is useful for predicting anomalous datapoints out of a large group. In order to do this, you need to\nhave training data…"}},{"node":{"frontmatter":{"title":"Machine Learning: Hypothesis, Cost Function, Gradient Descent Notes","createdAt":"2019-02-05T12:23:50.151Z","updatedAt":"2019-07-21T15:15:04.580Z","categories":["Programming","Algorithms","Machine Learning","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/hypothesis-cost-function-gradient-descent/"},"timeToRead":3,"excerpt":"Hypothesis The hypothesis is the prediction about a set of data. It is the  y  value on a graph in the house price example problem.\nIn the…"}},{"node":{"frontmatter":{"title":"Neural Networks","createdAt":"2019-02-26T14:20:26.310Z","updatedAt":"2019-07-21T15:08:47.860Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/neural-networks/"},"timeToRead":4,"excerpt":"Neural networks solve the problem in a different way than plain linear or logistic regression. With plain linear or\nlogistic regression, a…"}},{"node":{"frontmatter":{"title":"Matrices and Vectors: Linear Algebra Basics Review","createdAt":"2019-02-05T16:03:28.765Z","updatedAt":"2019-07-21T15:06:29.311Z","categories":["Machine Learning","Math"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/matrices-and-vectors/"},"timeToRead":1,"excerpt":"vectors are an  [n x 1]  matrix matrix addition only works on matrices of the same dimension matrix multiplication/division by a scalar…"}},{"node":{"frontmatter":{"title":"Machine Learning: Thinking About Design","createdAt":"2019-03-14T01:56:11.402Z","updatedAt":"2019-07-21T15:05:33.995Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/before-building/"},"timeToRead":2,"excerpt":"Before starting to build a network, it would be best to think very carefully about how to best go about it by\nbrainstorming and testing…"}},{"node":{"frontmatter":{"title":"Evaluation and Troubleshooting","createdAt":"2019-03-14T01:56:11.402Z","updatedAt":"2019-07-21T15:04:03.921Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/evaluation-and-troubleshooting/"},"timeToRead":2,"excerpt":"When troubleshooting the performance of a learning algorithm, it is best to try to narrow down the vause before jumping\nto conclusions about…"}},{"node":{"frontmatter":{"title":"Logistic Regression","createdAt":"2019-02-15T12:38:13.957Z","updatedAt":"2019-07-21T15:02:06.877Z","categories":["Programming","Algorithms","Machine Learning","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/logistic-regression/"},"timeToRead":1,"excerpt":"Logistic Regression Linear regression is good for predicting values that have a linear relationship to the data. In classification\nproblems…"}},{"node":{"frontmatter":{"title":"Unsupervised Learning: Clustering","createdAt":"2019-03-19T14:00:27.341Z","updatedAt":"2019-07-21T15:01:20.190Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/unsupervised-learning-clustering/"},"timeToRead":1,"excerpt":"K-Means Algorithm This algorithm starts with some points called cluster centroids, which will be the center point (average) of all of the…"}},{"node":{"frontmatter":{"title":"Support Vector Machines","createdAt":"2019-03-18T12:20:32.908Z","updatedAt":"2019-07-21T15:00:24.383Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/support-vector-machines/"},"timeToRead":2,"excerpt":"Support Vector Machines are also known as large margin classifiers because they increase the margin of the decision\nboundary. In the image…"}},{"node":{"frontmatter":{"title":"Data Compression and Dimension Reduction","createdAt":"2019-03-19T14:00:27.341Z","updatedAt":"2019-07-21T14:59:13.079Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/data-compression-dimension-reduction/"},"timeToRead":3,"excerpt":"It can be useful to compress feature data for the reasons of saving space, memory, and compute power when\nrunning machine learning…"}},{"node":{"frontmatter":{"title":"Multivariate Regression Analysis","createdAt":"2019-02-06T15:07:03.555Z","updatedAt":"2019-07-21T14:58:16.780Z","categories":["Machine Learning","Algorithms","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/multivariate-regression/"},"timeToRead":1,"excerpt":"every feature in a machine learning model should have a scale of approximately -1 to 1 in order to make the gradient\ndescent an easier…"}},{"node":{"frontmatter":{"title":"Working With Large Datasets","createdAt":"2019-04-05T03:54:53.273Z","updatedAt":"2019-07-21T14:50:42.464Z","categories":["Programming","Algorithms","Machine Learning","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/large-datasets/"},"timeToRead":1,"excerpt":"When working with large datasets, it can be computationally expensive, so it is best to figure out how many training\nexamples you need…"}},{"node":{"frontmatter":{"title":"ORACLE","createdAt":"2019-03-26T03:47:48.013Z","updatedAt":"2019-07-21T14:24:52.075Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks"]},"fields":{"slug":"/blog/notes/ORACLE/"},"timeToRead":2,"excerpt":"The Problem expanding neural networks to learn new tasks. past work includes advanced regularizations to prevent drastic changes in existing…"}},{"node":{"frontmatter":{"title":"Pattern Recognition and Machine Learning: Chapter 1 Exercises","createdAt":"2019-05-28T03:05:11.506Z","updatedAt":"2019-06-05T01:33:30.658Z","categories":["Pattern Recognition","Machine Learning","Exercises","Chapter 1"]},"fields":{"slug":"/blog/pattern-recognition-and-machine-learning-notes/chapter-1-exercises/"},"timeToRead":1,"excerpt":"1.1"}}]}},"pageContext":{"tagRegex":"/^Machine Learning$/i","tagName":"machine-learning"}}}