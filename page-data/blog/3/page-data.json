{"componentChunkName":"component---src-pages-blog-tsx","path":"/blog/3","result":{"data":{"site":{"siteMetadata":{"title":"Jeff Willette","description":"developer blog for Jeff Willette","keywords":"Jeff Willette,jeffwillette.github.io","author":"Jeff Willette"}},"allMdx":{"edges":[{"node":{"frontmatter":{"title":"Anomaly Detection","createdAt":"2019-03-20T14:26:44.585Z","updatedAt":"2019-07-21T15:16:49.628Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/anomaly-detection/"},"timeToRead":1,"excerpt":"Anomaly detection is useful for predicting anomalous datapoints out of a large group. In order to do this, you need to\nhave training data…"}},{"node":{"frontmatter":{"title":"Machine Learning: Hypothesis, Cost Function, Gradient Descent Notes","createdAt":"2019-02-05T12:23:50.151Z","updatedAt":"2019-07-21T15:15:04.580Z","categories":["Programming","Algorithms","Machine Learning","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/hypothesis-cost-function-gradient-descent/"},"timeToRead":3,"excerpt":"Hypothesis The hypothesis is the prediction about a set of data. It is the  y  value on a graph in the house price example problem.\nIn the…"}},{"node":{"frontmatter":{"title":"Neural Networks","createdAt":"2019-02-26T14:20:26.310Z","updatedAt":"2019-07-21T15:08:47.860Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/neural-networks/"},"timeToRead":4,"excerpt":"Neural networks solve the problem in a different way than plain linear or logistic regression. With plain linear or\nlogistic regression, a…"}},{"node":{"frontmatter":{"title":"Matrices and Vectors: Linear Algebra Basics Review","createdAt":"2019-02-05T16:03:28.765Z","updatedAt":"2019-07-21T15:06:29.311Z","categories":["Machine Learning","Math"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/matrices-and-vectors/"},"timeToRead":1,"excerpt":"vectors are an  [n x 1]  matrix matrix addition only works on matrices of the same dimension matrix multiplication/division by a scalar…"}},{"node":{"frontmatter":{"title":"Machine Learning: Thinking About Design","createdAt":"2019-03-14T01:56:11.402Z","updatedAt":"2019-07-21T15:05:33.995Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/before-building/"},"timeToRead":2,"excerpt":"Before starting to build a network, it would be best to think very carefully about how to best go about it by\nbrainstorming and testing…"}},{"node":{"frontmatter":{"title":"Evaluation and Troubleshooting","createdAt":"2019-03-14T01:56:11.402Z","updatedAt":"2019-07-21T15:04:03.921Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/evaluation-and-troubleshooting/"},"timeToRead":2,"excerpt":"When troubleshooting the performance of a learning algorithm, it is best to try to narrow down the vause before jumping\nto conclusions about…"}},{"node":{"frontmatter":{"title":"Logistic Regression","createdAt":"2019-02-15T12:38:13.957Z","updatedAt":"2019-07-21T15:02:06.877Z","categories":["Programming","Algorithms","Machine Learning","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/logistic-regression/"},"timeToRead":1,"excerpt":"Logistic Regression Linear regression is good for predicting values that have a linear relationship to the data. In classification\nproblems…"}},{"node":{"frontmatter":{"title":"Unsupervised Learning: Clustering","createdAt":"2019-03-19T14:00:27.341Z","updatedAt":"2019-07-21T15:01:20.190Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/unsupervised-learning-clustering/"},"timeToRead":1,"excerpt":"K-Means Algorithm This algorithm starts with some points called cluster centroids, which will be the center point (average) of all of the…"}},{"node":{"frontmatter":{"title":"Support Vector Machines","createdAt":"2019-03-18T12:20:32.908Z","updatedAt":"2019-07-21T15:00:24.383Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/support-vector-machines/"},"timeToRead":2,"excerpt":"Support Vector Machines are also known as large margin classifiers because they increase the margin of the decision\nboundary. In the image…"}},{"node":{"frontmatter":{"title":"Data Compression and Dimension Reduction","createdAt":"2019-03-19T14:00:27.341Z","updatedAt":"2019-07-21T14:59:13.079Z","categories":["Programming","Algorithms","Machine Learning","Neural Networks","Stanford"]},"fields":{"slug":"/blog/stanford-machine-learning-notes/data-compression-dimension-reduction/"},"timeToRead":3,"excerpt":"It can be useful to compress feature data for the reasons of saving space, memory, and compute power when\nrunning machine learning…"}}]}},"pageContext":{"page":3,"pageSlugs":[{"path":"/blog","page":1},{"path":"/blog/2","page":2},{"path":"/blog/3","page":3},{"path":"/blog/4","page":4},{"path":"/blog/5","page":5},{"path":"/blog/6","page":6},{"path":"/blog/7","page":7},{"path":"/blog/8","page":8},{"path":"/blog/9","page":9},{"path":"/blog/10","page":10},{"path":"/blog/11","page":11},{"path":"/blog/12","page":12},{"path":"/blog/13","page":13},{"path":"/blog/14","page":14},{"path":"/blog/15","page":15}],"limit":10,"skip":20}}}